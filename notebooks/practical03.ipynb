{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import string\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import sklearn\n",
    "\n",
    "## add your packages ##\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import memory_profiler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this line is just to test if the git upload works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../results/variables\")\n",
    "figures_path = Path(\"../results/figures\")\n",
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"matplotlib_style.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data\n",
    "\n",
    "We are going to use the multimodal data from the paper Scala et al. 2021 (https://www.nature.com/articles/s41586-020-2907-3#Sec7). In particular, you will work with transcriptomics and electrophysiological data. From the transcriptomics gene counts, we will only work with the exon counts for simplicity. Some of the electrophysiological features are not high-quality recordings, therefore we will also filter them out for the project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# META DATA\n",
    "\n",
    "meta = pd.read_csv(data_path / \"m1_patchseq_meta_data.csv\", sep=\"\\t\")\n",
    "\n",
    "cells = meta[\"Cell\"].values\n",
    "\n",
    "layers = meta[\"Targeted layer\"].values.astype(\"str\")\n",
    "cre = meta[\"Cre\"].values\n",
    "yields = meta[\"Yield (pg/µl)\"].values\n",
    "yields[yields == \"?\"] = np.nan\n",
    "yields = yields.astype(\"float\")\n",
    "depth = meta[\"Soma depth (µm)\"].values\n",
    "depth[depth == \"Slice Lost\"] = np.nan\n",
    "depth = depth.astype(float)\n",
    "thickness = meta[\"Cortical thickness (µm)\"].values\n",
    "thickness[thickness == 0] = np.nan\n",
    "thickness = thickness.astype(float)\n",
    "traced = meta[\"Traced\"].values == \"y\"\n",
    "exclude = meta[\"Exclusion reasons\"].values.astype(str)\n",
    "exclude[exclude == \"nan\"] = \"\"\n",
    "\n",
    "mice_names = meta[\"Mouse\"].values\n",
    "mice_ages = meta[\"Mouse age\"].values\n",
    "mice_cres = np.array(\n",
    "    [\n",
    "        c if c[-1] != \"+\" and c[-1] != \"-\" else c[:-1]\n",
    "        for c in meta[\"Cre\"].values\n",
    "    ]\n",
    ")\n",
    "mice_ages = dict(zip(mice_names, mice_ages))\n",
    "mice_cres = dict(zip(mice_names, mice_cres))\n",
    "\n",
    "print(\"Number of cells with measured depth:    \", np.sum(~np.isnan(depth)))\n",
    "print(\"Number of cells with measured thickness:\", np.sum(~np.isnan(thickness)))\n",
    "print(\"Number of reconstructed cells:          \", np.sum(traced))\n",
    "\n",
    "sliceids = meta[\"Slice\"].values\n",
    "a, b = np.unique(sliceids, return_counts=True)\n",
    "assert np.all(b <= 2)\n",
    "print(\"Number of slices with two cells:        \", np.sum(b == 2))\n",
    "\n",
    "# Some consistency checks\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Date\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse age\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse gender\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse genotype\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse\"].values[sliceids == s]).size == 1\n",
    "        for s in sliceids\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcriptomic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ COUNTS\n",
    "\n",
    "data_exons = pd.read_csv(\n",
    "    data_path / \"m1_patchseq_exon_counts.csv.gz\", na_filter=False, index_col=0\n",
    ")\n",
    "exonCounts = data_exons.values.transpose()\n",
    "\n",
    "assert all(cells == data_exons.columns)\n",
    "genes = np.array(data_exons.index)\n",
    "\n",
    "print(\"Count matrix shape (exon):  \", exonCounts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENE LENGTH\n",
    "\n",
    "data = pd.read_csv(data_path / \"gene_lengths.txt\")\n",
    "assert all(data[\"GeneID\"] == genes)\n",
    "exonLengths = data[\"exon_bp\"].values\n",
    "intronLengths = data[\"intron_bp\"].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = np.load(data_path / \"cluster_colors.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_type = np.load(data_path / \"rna_type.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_type.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(data_path / \"dict_rna_type_colors.pkl\", \"rb\")\n",
    "dict_rna_type_colors = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_rna_type_colors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electrophysiological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPHYS DATA\n",
    "\n",
    "ephysData = pd.read_csv(data_path / \"m1_patchseq_ephys_features.csv\")\n",
    "ephysNames = np.array(ephysData.columns[1:]).astype(str)\n",
    "ephysCells = ephysData[\"cell id\"].values\n",
    "ephysData = ephysData.values[:, 1:].astype(\"float\")\n",
    "names2ephys = dict(zip(ephysCells, ephysData))\n",
    "ephysData = np.array(\n",
    "    [\n",
    "        names2ephys[c] if c in names2ephys else ephysData[0] * np.nan\n",
    "        for c in cells\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Number of cells with ephys data:\", np.sum(np.isin(cells, ephysCells)))\n",
    "\n",
    "assert np.sum(~np.isin(ephysCells, cells)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering ephys data\n",
    "\n",
    "features_exclude = [\n",
    "    \"Afterdepolarization (mV)\",\n",
    "    \"AP Fano factor\",\n",
    "    \"ISI Fano factor\",\n",
    "    \"Latency @ +20pA current (ms)\",\n",
    "    \"Wildness\",\n",
    "    \"Spike frequency adaptation\",\n",
    "    \"Sag area (mV*s)\",\n",
    "    \"Sag time (s)\",\n",
    "    \"Burstiness\",\n",
    "    \"AP amplitude average adaptation index\",\n",
    "    \"ISI average adaptation index\",\n",
    "    \"Rebound number of APs\",\n",
    "]\n",
    "features_log = [\n",
    "    \"AP coefficient of variation\",\n",
    "    \"ISI coefficient of variation\",\n",
    "    \"ISI adaptation index\",\n",
    "    \"Latency (ms)\",\n",
    "]\n",
    "\n",
    "X = ephysData\n",
    "print(X.shape)\n",
    "for e in features_log:\n",
    "    X[:, ephysNames == e] = np.log(X[:, ephysNames == e])\n",
    "X = X[:, ~np.isin(ephysNames, features_exclude)]\n",
    "\n",
    "keepcells = ~np.isnan(np.sum(X, axis=1))\n",
    "X = X[keepcells, :]\n",
    "print(X.shape)\n",
    "\n",
    "X = X - X.mean(axis=0)\n",
    "ephysData_filtered = X / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(ephysData_filtered))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research questions to investigate\n",
    "\n",
    "**1) Inspect the data computing different statistics.** Keep in mind that the data is read counts, not UMI, so it is not supposed to follow a Poisson distribution.\n",
    "\n",
    "**2) Normalize and transform the data.** There are several ways of normalizing the data (Raw, CPM, CPMedian, RPKM, see https://www.reneshbedre.com/blog/expression_units.html, https://translational-medicine.biomedcentral.com/articles/10.1186/s12967-021-02936-w). Take into account that there are certain normalizations that only make sense for UMI data. You also explored different transformations in the assignment (none, log, sqrt). Compare how the different transformations change the two-dimensional visualization.\n",
    "\n",
    "**3) Two-dimensional visualization.** Try different methods (t-SNE, UMAP) / parameters (exagg., perplex.) for visualizations. Compare them using quantitative metrics (e.g., distance correlation, kNN accuracy/recall in high-dim vs. two-dim). Think about also using the electrophysiological features for different visualizations.\n",
    "\n",
    "**4) Clustering.** Try different clustering methods (leiden, GMM). Implement a negative binomial mixture model. For that you can follow a similar method that what is described in Harris et al. 2018 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2006387#abstract0), with fixed r (r=2) and S (set of important genes). Evaluate your clustering results (metrics, compare number of clusters to original labels,...).\n",
    "\n",
    "**5) Correlation in between electrophysiological features and genes/PCs.** Find correlations and a way of visualizing them.\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
